library(argparse)

parser <- ArgumentParser("This script generates individual excel sheets for each sample and hellingerMatrix.Rda file from fasta and vcf files")
parser$add_argument("source", type = "character", help = "The source directory containing the seqtrack directory")
parser$add_argument("--num_clusters", type = "integer", help = "The number of cores to be used by parallel function")
args <- parser$parse_args()

src <- args$source
num_partitions <- length(list.dirs(paste0(src, "/seqtrack"), recursive = FALSE))
num_cl <- args$num_clusters


# input: masterlist:excel files containing sample names
# csvfromvcfdir: directory containing the data tables generated by the csv_datatable function
# sample number: number of samples
# outputloc: where to store resultant transmission tree
build_network <- function(masterlist, csvfromvcfdir, samplenumber, outputloc) {
  if (samplenumber == 1) {
    return()
  }
  library(adegenet)
  library(ape)
  library(data.table)
  library(visNetwork)
  library(stringr)
  library(webshot)
  library(tidyverse)
  library(readxl)
  library(hash)

  # Master List #To do: set sample no=number of csv file
  ref <- read_excel(masterlist)
  dates <- as.Date(ref$ReleaseDate) # store release dates

  # modified is to identify the relevant file names
  # modified<<-purrr::map(ref$Accession,function(x)paste0(str_sub(x,start=8,end=9),"_",str_sub(x,start=-2)))
  modified <<- purrr::map(ref$Accession, function(x) strsplit(x, "[.]")[[1]][1])
  # Construct List of Data Tables
  DTlist <- list()
  for (i in 1:samplenumber)
  {
    DTlist[[i]] <- fread(paste0(csvfromvcfdir, modified[[i]], ".csv")) # read in data table for each sample
  }

  # Functions to calculate Hellinger and Hamming Distance

  hamdst <- function(i1, i2) {
    tmp <- DTlist[[i1]][DTlist[[i2]], on = c(POSSN = "POSSN", nucleotide = "nucleotide")]
    tmp <- tmp[ref != "-" & i.ref != "-"]


    tmp2 <- unique(tmp[, .(POSSN, ref, i.ref)])
    return(mean(tmp2$ref != tmp2$i.ref))
  }
  hellidst <- function(i1, i2) {
    print(DTlist[[i1]])
    tmp <- DTlist[[i1]][DTlist[[i2]], on = c(POSSN = "POSSN", nucleotide = "nucleotide")]
    tmp <- tmp[ref != "-" & i.ref != "-"]

    tmp2 <- tmp[, .(hd = sqrt(sum((sqrt(AF) - sqrt(i.AF))^2)) / sqrt(2)), by = .(Accession, i.Accession, POSSN)]
    return(mean(tmp2$hd))
  }
  # create data table
  dstmtx <- data.table(
    i1 = rep(1:nrow(ref), each = nrow(ref)), i2 = rep(1:nrow(ref), nrow(ref)),
    Accession1 = rep(ref$Accession, each = nrow(ref)), Accession2 = rep(ref$Accession, nrow(ref))
  )
  # data table if geographical information is of interest:
  "dstmtx = data.table(i1 = rep(1:nrow(ref), each = nrow(ref)), i2 = rep(1:nrow(ref), nrow(ref)),
                    Library1 = rep(ref$Library, each = nrow(ref)), Library2 = rep(ref$Library, nrow(ref)),
                    `House ID1` = rep(ref$`House ID`, each = nrow(ref)), `House ID2` = rep(ref$`House ID`, nrow(ref)),
                    `House Category1` = rep(ref$`House Category`, each = nrow(ref)),
                    `House Category2` = rep(ref$`House Category`, nrow(ref)),
                    LATITUD1 = rep(ref$LATITUD, each = nrow(ref)), LATITUD2 = rep(ref$LATITUD, nrow(ref)),
                    LONGITUD1 = rep(ref$LONGITUD, each = nrow(ref)), LONGITUD2 = rep(ref$LONGITUD, nrow(ref)),
                    FTM1 = rep(ref$FTM, each = nrow(ref)), FTM2 = rep(ref$FTM, nrow(ref)))"

  dstmtx <- dstmtx[i1 != i2] # make sure i1 and i2 are not of the same value
  dstmtx <- dstmtx[!(i1 > i2)] # only include where i2>i1
  print(dstmtx)
  dstmtx[, hammdst := mapply(hamdst, i1, i2, SIMPLIFY = FALSE)] # calculate hamming distance per row
  dstmtx[, helldst := mapply(hellidst, i1, i2, SIMPLIFY = FALSE)] # calculate hellinger distance per row
  print(dstmtx)

  # calculate difference in date and geographical location:
  "
dstmtx[, daydiff := as.numeric(as.Date(FTM2) - as.Date(FTM1))]
dstmtx[, spacediff := mapply(function(LONGITUD1, LATITUD1, LONGITUD2, LATITUD2)
  distm(c(LONGITUD1, LATITUD1), c(LONGITUD2, LATITUD2), fun = distHaversine),
  LONGITUD1, LATITUD1, LONGITUD2, LATITUD2) / 1000]
  "

  # Create Matrix:
  D <- data.table(accession = ref$Accession) # create accession column, 1 row per sample

  for (i in 1:samplenumber)
  {
    D[, ref$Accession[i] := 0] # give each sample a single column.
    # Each sample has 32 rows excluding the column header row
    # this is necessary so that the hellinger distance between the sample in the column name
    # and the sample in the correspondig row can be stored
  }

  for (i in 1:nrow(dstmtx))
  {
    D[dstmtx[i]$i1, dstmtx[i]$i2 + 1 := dstmtx[i]$helldst]
    D[dstmtx[i]$i2, dstmtx[i]$i1 + 1 := dstmtx[i]$helldst]
    # calculate space difference divided by day difference:
    # D2[as.character(dstmtx[FTM1<FTM2]$i1[i]), as.character(dstmtx[FTM1<FTM2]$i2[i])] =
    # dstmtx[FTM1<FTM2]$spacediff[i] / dstmtx[FTM1<FTM2]$daydiff[i]
    # if difference in day is less than 4, take the maximum hellinger distance:
    # D3[as.character(dstmtx[FTM1<FTM2]$i1[i]), as.character(dstmtx[FTM1<FTM2]$i2[i])] =
    #  ifelse(dstmtx[FTM1<FTM2]$daydiff[i] >= 4, dstmtx[FTM1<FTM2]$helldst[i], max(dstmtx[FTM1<FTM2]$helldst))
  }

  D[, accession := NULL]

  D <- as.data.frame.matrix(D)
  D2 <- as.matrix(D) # Store geographic distance

  row.names(D) <- ref$Accession


  Dmat <- as.matrix(D)
  print(Dmat) # matrix
  save(Dmat, file = paste0(outputloc, "hellingerMatrix.Rda")) # load with load('hM.Rda')
  return(NA)
  # print(Dmat)

  # scft = max(dstmtx[FTM1 < FTM2]$helldst) * min(dstmtx[FTM1 < FTM2]$daydiff) # scale factor
  # scft = max(dstmtx[FTM1 < FTM2]$helldst) / max(dstmtx[FTM1 < FTM2]$spacediff / dstmtx[FTM1 < FTM2]$daydiff) # scale factor


  dscft <- c()
  for (h in dstmtx$helldst) {
    dscft <- c(dscft, as.integer(strsplit(as.character(h), "e-")[[1]][2]))
  }
  dscft <- max(dscft)
  print(dscft)
  mysqtk <- list()
  # barriosens = list()
  sqtkindex <- sort(which(month(ref$ReleaseDate) %in% c(1:12)))
  # dscft<-max(dstmtx$helldst)
  # dscft<-max(dstmtx[FTM1 < FTM2]$helldst) / max(dstmtx[FTM1 < FTM2]$spacediff / dstmtx[FTM1 < FTM2]$daydiff) # scale factor

  # seqTrack
  for (i in 1:101)
  {
    Dmtx <- Dmat + seq(0, 1, 0.01)[i] * dscft * D2
    mysqtk[[i]] <- seqTrack(Dmtx, x.names = ref$Accession, x.dates = as.Date(ref$ReleaseDate)[sqtkindex], best = "min")
    mysqtk[[i]] <- as.data.table(mysqtk[[i]])
    mysqtk[[i]][, daydiff := as.numeric(date - ances.date)]
    mysqtk[[i]][, ":="(i1 = sqtkindex[ances], i2 = sqtkindex[id])]
    cgmrt <- ref
    # for when geographical data is given:
    '
  mysqtk[[i]][, ":="(`House ID1` = cgmrt$`House ID`[i1], `House ID2` = cgmrt$`House ID`[i2],
                     `Participant ID1` = cgmrt$`Participant ID`[i1], `Participant ID2` = cgmrt$`Participant ID`[i2],
                     BARRIO1 = cgmrt$BARRIO[i1], BARRIO2 = cgmrt$BARRIO[i2],
                     LATITUD1 = cgmrt$LATITUD[i1], LATITUD2 = cgmrt$LATITUD[i2],
                     LONGITUD1 = cgmrt$LONGITUD[i1], LONGITUD2 = cgmrt$LONGITUD[i2],
                     FTM1 = cgmrt$FTM[i1], FTM2 = cgmrt$FTM[i2])]
  mysqtk[[i]] = mysqtk[[i]][!is.na(daydiff), .(i1, i2, `House ID1`, `House ID2`, `Participant ID1`, `Participant ID2`,
                                               `BARRIO1`, `BARRIO2`, `LONGITUD1`, `LONGITUD2`, `LATITUD1`, `LATITUD2`,
                                               FTM1, FTM2, daydiff, weight)]

  mysqtk[[i]][, i1i2 := paste(i1, i2, sep = "_")]
  barriosens[[i]] = mysqtk[[i]][daydiff %in% 4:28, .N, by = .(BARRIO1, BARRIO2)][barriodt0,
                                                                                 on = c(BARRIO1 = "BARRIO1", BARRIO2 = "BARRIO2")]
  barriosens[[i]][is.na(N), N := 0]

  barriosens[[i]][, ":="(Nsum = sum(N)), by = .(BARRIO2)]
  barriosens[[i]][, ":="(p = N/Nsum)]
                     '
  }

  'barriosensdt = do.call("rbind", lapply(1:101, function(i) barriosens[[i]][, .(BARRIO1, BARRIO2, N)]))
barriosensdt = barriosensdt[, .(N = sum(N)), by = .(BARRIO1, BARRIO2)]
barriosensdt[, ":="(Nsum = sum(N)), by = .(BARRIO2)]
barriosensdt[, ":="(p = N/Nsum)]

mysqtkdt = do.call("rbind", lapply(1:101, function(i) mysqtk[[i]]))
mysqtk[[1]][, robust := sapply(i1i2, function(x) nrow(mysqtkdt[i1i2 == x])/101)]'

  # SeqTrack:
  lofrq <- seqTrack(Dmat, x.names = modified, x.dates = dates, best = "min")
  nodes <- data.frame(
    id = 1:samplenumber,
    label = unlist(modified), font.size = 30,
    shape = "circle",
    colour = "yellow",
    shadow = FALSE
  )
  edges <- data.frame(
    from = dstmtx$i1, to = dstmtx$i2, length = 200,
    width = unlist(dstmtx$helldst) # set width to correspond to hellinger distance
    , arrows = "to",
    dashes = FALSE,
    smooth = FALSE,
    shadow = FALSE
  )

  y <- edges[order(edges$width), ] # order hellinger distance in increasing order
  x <- edges[order(edges$width), ] # order hellinger distance in increasing order
  # we use increasing order since the larger the hellinger distance the smaller the probability
  # of transmission thus, the smaller widths would be preferred.
  store <- hash() # hash contains key value pairs. key: node values
  # Value: nodes accessible by the node in the key

  findpath <- function(start, end, ht) {
    # check if there is already a path from start node to end node
    # output true if there is already a path from start to end and false otherwise
    n <- start
    flag <- FALSE
    n <- start
    visitedkey <- c()
    while (!(end %in% n) & length(intersect(start, hash::values(ht))) >= 1) {
      ni <- c()
      for (k in hash::keys(ht)) {
        visitedkey <- c(visitedkey, k)
        if (length(intersect(ht[[k]], n)) >= 1) {
          ni <- c(ni, k)
          print(ni)
        }
      }
      n <- ni
      if (length(n) == 0) {
        break
      }
    }
    if (end %in% n) {
      flag <- TRUE
    }
    if (start %in% hash::keys(ht)) {
      if (end %in% ht[[toString(start)]]) {
        flag <- TRUE
      }
    }

    return(flag)
  }

  visited <- c()
  toremove <- c()
  for (r in 1:nrow(y)) {
    # loop through each row to find which rows are irrelevant for final tree
    # this ensures that each node only has one arrow pointing to it so that the final
    # output is a hierarchical tree

    front <- y[r, ]$from
    taill <- y[r, ]$to

    if (length(unique(visited)) == samplenumber) {
      # we break the loop when all the samples have already been accounted for
      break
    } else {
      # we ignore if there is already a path from front to taill or there is already an arrow pointing to taill
      if (findpath(front, taill, store) | (taill %in% visited)) {
        toremove <- c(toremove, r)
      } else {
        # if not we need to join front to taill and update the visited values and store the
        # fact that taill can be accessed by front
        visited <- c(visited, taill)
        print(visited)
        if (has.key(toString(front), store)) {
          store[[toString(front)]] <- c(store[[toString(front)]], taill)
        } else {
          store[[toString(front)]] <- c()
          store[[toString(front)]] <- c(store[[toString(front)]], taill)
        }
      }
    }
  }
  x <- x[-toremove, ]
  # remove irrelevant rows and we should be left with the same number of rows as the number of samples

  newwidths <- seq(from = 10, to = 10 / length(rownames(x)), by = -10 / length(rownames(x)))
  # create new widths for the final network, the larger the width, the higher the probability of trasmission
  x$width <- newwidths
  network <<- visNetwork(nodes, x, height = "1000px", width = "100%", main = list(text = "LoFreq", style = "font-family:Comic Sans MS;color:blue;font-size:25px;text-align:left;"))
  network <<- network %>%
    visHierarchicalLayout(direction = "LR") %>%
    visPhysics(enabled = FALSE)
  # store viNetwork in html file
  fname <- paste0("network", ".html")
  visSave(network, fname)
  # save html file as png file:
  webshot(fname,
    delay = 0.5, zoom = 2, file = paste0("faster", ".png"),
    vwidth = 900, vheight = 900
  )
  # move file to the outputloc folder:
  file.copy(paste0(getwd(), "/", "faster.png"), outputloc, overwrite = TRUE)
  file.remove(paste0(getwd(), "/", "faster.png"))
  return(dstmtx)
}

finalfn <- function(inputfiledir, vcfinputfilename, fastainputfilename, outputfiledir, numclusters) {
  library(stringr)
  library(readr)
  library(foreach)
  library(doParallel)
  library(parallel)
  library(bench) # for benchmarking

  # storing directories for each of the file types
  masterexcelfile <- paste0(inputfiledir, list.files(inputfiledir, ".xlsx"))
  vcffiles <- list.files(paste0(inputfiledir, vcfinputfilename, "/"), ".vcf")
  fastafiles <- list.files(paste0(inputfiledir, fastainputfilename, "/"), ".fasta")

  reffile <- readxl::read_excel(masterexcelfile)
  vcfnames <- c()
  fastanames <- c()
  # check if each vcf has a corresponding fasta file:
  for (vcf in vcffiles) {
    fileName <- basename(vcf)
    name <- strsplit(fileName, "[.]")[[1]][1]
    # name<-str_extract(vcf,".*?(\\d+)_.*?(\\d+)")
    vcfnames <- c(vcfnames, name)
  }
  for (fasta in fastafiles) {
    fileName <- basename(fasta)
    name <- strsplit(fileName, "[.]")[[1]][1]
    # name<-str_extract(fasta,".*?(\\d+)_.*?(\\d+)")
    fastanames <- c(fastanames, name)
  }
  if (!setequal(vcfnames, fastanames)) { # terminate if files are missing
    print("Error missing files")
    if (length(setdiff(vcfnames, fastanames)) >= 1) {
      print(paste0("missing fasta files:", setdiff(vcfnames, fastanames)))
    } else {
      print(paste0("missing vcf files:", setdiff(fastanames, vcfnames)))
    }
  } else {
    library(data.table)
    library(readxl)
    names <- unlist(reffile$Accession) # obtain sample names
    samplenumber <- length(names)

    # windsor's code
    'for(sample in names){
      print(sample)
      csv_datatable(sample,paste0(inputfiledir,fastainputfilename,"/"),paste0(inputfiledir,vcfinputfilename,"/"),outputfiledir,".csv")
    }'

    # parallel code
    foreach_csv_datatable <- function(names, numofclusters, dr, inputfiledir, vcfinputfilename, fastainputfilename, outputfiledir) {
      library(readr)

      # function to create individual csv datatables
      csv_datatable <- function(accessionno, fastadirpath, vcfdirpath, destdirpath, suffix) {
        library(seqinr)
        library(stringr)

        seq_list <- list() # to store fasta sequence

        fastapath <- paste0(fastadirpath, accessionno, ".lofreq.fasta")
        seqlist <- read.fasta(file = fastapath, seqonly = TRUE) # read in fasta sequence only eg ANCTG
        seq_list <- tolower(seqlist[[1]]) # convert sequence to lower case eg anctg

        #### Construct data frame using the information from fasta file####
        #<<- means these are global variables and so can be modified inside the function and still be accessible outside functions
        accession <<- c()
        possn <<- c()
        nucleotide <<- c()
        AF <<- c()
        refv <<- c()

        # function to add the corresponding rows depending whether the reference
        # nucleotide in the sequence is a,t,c,g,i or -.
        # input: number=sample name, position=position of nucleotide,
        # reference= reference nucleotide which is the nucleotide at that position in the fasta seq,
        # accession,possn,nucleotide,AF,refv=global vectors to store the output
        addregular <- function(number, position, reference, accession, possn, nucleotide, AF, refv) {
          # since each position needs 6 rows, one for each of a,t,c,g,i and d
          accession <<- c(accession, rep(accessionno, 6)) # add sample number 6 times per function call
          possn <<- c(possn, rep(position, 6)) # add position number 6 times per function call
          nucleotidelist <- c("a", "t", "c", "g", "i", "d")
          nucleotide <<- c(nucleotide, nucleotidelist)

          # the allele frequency of the reference allele at the position needs to be set to 1
          # and the remaining nucleotides have allele frequency of 0:
          AFadd <- rep("0.000000", 6)
          tosetto1 <- which(nucleotidelist == reference)
          AFadd[tosetto1] <- "1.000000"
          AF <<- c(AF, AFadd)

          refv <<- c(refv, rep(reference, 6)) # add reference nucleotide at that position 6 times per function call
        }
        # function to add the corresponding rows depending whether the reference
        # nucleotide in the sequence is n,r,y,k,m,s,w.
        # separate function since the allele frequencies of a,c,t,g,i,d differ depending on the reference nucleotide
        # input: number=sample name, position=position of nucleotide,
        # reference=reference nucleotide at that postiion,
        # accession,possn,nucleotide,AF,refv=global vectors to store the output
        addspecial <- function(number, position, reference, accession, possn, nucleotide, AF, refv) {
          accession <<- c(accession, rep(accessionno, 6))
          possn <<- c(possn, rep(position, 6))
          nucleotidelist <- c("a", "t", "c", "g", "i", "d")
          nucleotide <<- c(nucleotide, nucleotidelist)
          if (reference == "n") {
            AFadd <- c(rep("0.250000", 4), rep("0.000000", 2))
          } else {
            AFadd <- rep("0.000000", 6)
            if (reference == "r") {
              tochange <- c("a", "g")
            } else if (reference == "y") {
              tochange <- c("t", "c")
            } else if (reference == "k") {
              tochange <- c("t", "g")
            } else if (reference == "m") {
              tochange <- c("a", "c")
            } else if (reference == "s") {
              tochange <- c("g", "c")
            } else if (reference == "w") {
              tochange <- c("a", "t")
            }
            AFadd[which(nucleotidelist == tochange)] <- "0.500000"
          }
          AF <<- c(AF, AFadd)
          refv <<- c(refv, rep(reference, 6))
        }

        for (j in 1:nchar(seq_list)) {
          # loop through each nucleotide in the fasta sequence
          # add 6 values to each of the accession,possn,nucleotide,AF,refv global vectors for each position

          if (substr(seq_list, j, j) == "a") {
            # if the nucleotide at position j is a:
            addregular(accessionno, j, "a", accession, possn, nucleotide, AF, refv)
          } else if (substr(seq_list, j, j) == "t") {
            # if the nucleotide at position j is t:
            addregular(accessionno, j, "t", accession, possn, nucleotide, AF, refv)
          } else if (substr(seq_list, j, j) == "c") {
            # if the nucleotide at position j is c:
            addregular(accessionno, j, "c", accession, possn, nucleotide, AF, refv)
          } else if (substr(seq_list, j, j) == "g") {
            # if the nucleotide at position j is g:
            addregular(accessionno, j, "g", accession, possn, nucleotide, AF, refv)
          } else if (substr(seq_list, j, j) == "-") {
            # if the nucleotide at position j is - we denote - by d in the data table
            addregular(accessionno, j, "d", accession, possn, nucleotide, AF, refv)
          } else if (substr(seq_list, j, j) == "n") {
            # if the nucleotide at position j is n each of the nucleotides a,t,c,g are equally likely:
            addspecial(accessionno, j, "n", accession, possn, nucleotide, AF, refv)
          } else if (substr(seq_list, j, j) == "r") {
            # if the nucleotide at position j is r, the nucleotide is equally likely to be A/G(purine)
            addspecial(accessionno, j, "r", accession, possn, nucleotide, AF, refv)
          } else if (substr(seq_list, j, j) == "y") {
            # if the nucleotide at position j is y, the nucleotide is equally likely to be C/T(pyrimidine)
            addspecial(accessionno, j, "y", accession, possn, nucleotide, AF, refv)
          } else if (substr(seq_list, j, j) == "k") {
            # if the nucleotide at position j is k, the nucleotide is equally likely to be G/T
            addspecial(accessionno, j, "k", accession, possn, nucleotide, AF, refv)
          } else if (substr(seq_list, j, j) == "m") {
            # if the nucleotide at position j is m, the nucleotide is equally likely to be A/C
            addspecial(accessionno, j, "m", accession, possn, nucleotide, AF, refv)
          } else if (substr(seq_list, j, j) == "s") {
            # if the nucleotide at position j is s, the nucleotide is equally likely to be G/C
            addspecial(accessionno, j, "s", accession, possn, nucleotide, AF, refv)
          } else if (substr(seq_list, j, j) == "w") {
            # if the nucleotide at position j is w, the nucleotide is equally likely to be A/T
            addspecial(accessionno, j, "w", accession, possn, nucleotide, AF, refv)
          }
        }
        # create data frame where each position has 6 rows
        # so that each position has a row for a,t,c,g,i and d and the corresponding allele frequency (AF) for the
        # nucleotide at that row
        df <- data.frame(accession, possn, nucleotide, AF, refv)

        # function to read in data from the vcf file:
        # input: path to vcf file
        # output: data table where there are 6 rows one for each of a,t,c,g,i,d for each variant position
        # and the corresponding allele frequencies for the nucleotide at a particular position
        extract_from_vcf <- function(vcf_path) {
          library(vcfR)
          library(stringr)
          library(hash)
          vcf <- read.vcfR(vcf_path) # read in vcf file as vcfR object consisting of 2 parts namely fix and gt
          fixed <- vcf@fix # store fix part of the vcfR object
          samp <- vcf@gt # store gt part of the vcfR object
          info <- hash() # hash table to store the values read in for construction of the resultant data table
          # hash table has 4 key value pairs. Keys: "POS","REF","ALT","AF". Values: lists
          info["POS"] <- list()
          info["REF"] <- list()
          info["ALT"] <- list()
          info["AF"] <- list()
          # info["QUAL"]=list()
          for (record in 1:length(fixed[, "CHROM"])) { # loop through each row in the vcfR object

            alt <- fixed[record, "ALT"] # alternate allele
            ref <- fixed[record, "REF"] # reference allele
            pos <- fixed[record, "POS"] # position
            # qual<-fixed[record,"QUAL"] to store quality
            af <- NULL
            dp <- NULL
            ac <- NULL
            if (str_length(fixed[record, "INFO"]) > 1) {
              # if the fixed data table has more than one row, the vcf file contains AF,DP and AC values:
              tosplit <- fixed[record, "INFO"] # store AF=_;DP=_; as a single string
              # since the format of that position is AF=_;DP=_; we split the string by the delimiter ;
              for (v in str_split(tosplit, ";")[[1]]) {
                if (substr(v, 1, 2) == "AF") {
                  af <- substr(v, 4, str_length(v)) # extract and store AF value
                  break
                } else if (substr(v, 1, 2) == "DP") {
                  dp <- substr(v, 4, str_length(v)) # extract and store DP value
                } else if (substr(v, 1, 2) == "AC") {
                  # extract and store AC values
                  ac1 <- substr(v, 4, str_length(v))
                  acr <- as.numeric(str_split(ac1, ",")[[1]][1])
                  acv <- as.numeric(str_split(ac1, ",")[[1]][2])
                  totalac <- acr + acv
                } else if (substr(v, 1, 2) == "AM") {
                  # extract and store AM value
                  am <- substr(v, 4, str_length(v))
                  am <- as.numeric(am)
                }
              }
            } else {
              # if the vcf file has no info column, we use the information in the gt part of the vcfR object
              s <- samp[record, "SAMPLE"]
              spl <- str_split(s, ":")[[1]]
              af <- spl[length(spl)] # extract and store AF value
            }
            if (is.null(af)) { # if there is no AF value, we calculate the AF value from the AC and AM values
              denominator <- totalac + am
              af <- acv / denominator
            }
            # add resultant values to its corresponding list
            info[["POS"]] <- append(info[["POS"]], pos)
            info[["AF"]] <- append(info[["AF"]], af)
            info[["REF"]] <- append(info[["REF"]], ref)
            info[["ALT"]] <- append(info[["ALT"]], alt)
            # info[["QUAL"]]=append(info[["QUAL"]],qual)
          }

          # convert hash table to a data frame with columns: AF, ALT, POS and REF
          df <- as.data.frame(unlist(info[["AF"]]))
          df[, 2] <- unlist(info[["ALT"]])
          df[, 3] <- unlist(info[["POS"]])
          df[, 4] <- unlist(info[["REF"]])
          colnames(df) <- c("AF", "ALT", "POS", "REF") # rename columns

          freq <- df

          # keep only "ALRT" column with a single letter
          freq <- freq[sapply(freq$ALT, function(x) str_length(x) == 1), ]


          # convert data type of the AF and POS columns to numeric
          freq$AF <- lapply(freq$AF, function(x) as.numeric(as.character(x)))
          freq$POS <- lapply(freq$POS, function(x) as.numeric(as.character(x)))

          freqo <- freq[order(unlist(freq$AF), decreasing = TRUE), ] # order AF in descending order
          freq <- Reduce(rbind, by(freqo, unlist(freqo$POS), head, n = 1)) # group by POS value and take top row

          freq <- freq[order(unlist(freq$POS)), ] # order POS column in increasing order


          # get unique POS values
          POSs <- unique(freq$POS)

          current <- 0
          DFs <- list()
          for (freqr in rownames(freq)) {
            # loop through each row in the freq data table
            D <- hash("POSSN" = list(), "nucleotide" = list(), "AF" = list()) # new hash object to store modified list

            # calculate allele frequencies of the
            # reference and alternate alleles using the AF values stored previously
            for (necleo in c("a", "t", "c", "g", "i", "d")) {
              D[["POSSN"]] <- append(D[["POSSN"]], freq[freqr, "POS"]) # append position
              D[["nucleotide"]] <- append(D[["nucleotide"]], necleo)
              # append nucleotide for the current loop either a,t,c,g,i or d

              if (toupper(necleo) == freq[freqr, "ALT"]) {
                # convert nucleotide of the current iteration to upper case to check whether
                # it matches the alternate allele, it it does, the allele frequency of the nucleotide
                # in the current iteration is the AF value stored previously
                D[["AF"]] <- append(D[["AF"]], as.numeric(freq[freqr, "AF"]))
              } else if (toupper(necleo) == freq[freqr, "REF"]) {
                # convert nucleotide of the current iteration to upper case to check whether
                # it matches the reference allele, it it does, the allele frequency of the nucleotide
                # in the current iteration is the 1 minus the AF value stored previously
                D[["AF"]] <- append(D[["AF"]], 1 - as.numeric(freq[freqr, "AF"]))
              } else {
                # if the nucleotide of the current iteration is neither the reference of alternate
                # allele, the allele frequency of the nucleotide in the current iteration is 0
                D[["AF"]] <- append(D[["AF"]], 0)
              }
            }
            # create new data frame with the allele frequencies
            # of the alternate and reference allele incorportated.
            # one data frame per position
            DF <- as.data.frame(unlist(D[["AF"]]))
            DF[, 2] <- unlist(D[["POSSN"]])
            DF[, 3] <- unlist(D[["nucleotide"]])
            colnames(DF) <- c("AF", "POSSN", "nucleotide")
            # join the data frames for each position together
            if (length(DFs) > 1) {
              current <- rbind(current, DF)
              # join the data frame generated in this iteration by adding on to the bottom of the previous
              # data tables
            } else {
              current <- DF
            }
            DFs <- append(DFs, DF)
          }
          return(current)
        }
        library(dplyr)
        vcf_path <- paste0(vcfdirpath, accessionno, ".lofreq.vcf") # path to vcf file
        DF_ref <- extract_from_vcf(vcf_path)
        DF_source <- df # data frame from the fasta file
        colnames(DF_source) <- c("accession", "POSSN", "nucleotide", "AF", "ref") # change names of columns
        DF_ref$POSSN <- as.double(DF_ref$POSSN) # convert the position values to type double
        DF_source$AF <- as.double(DF_source$AF) # convert the AF values to type double
        temp <- left_join(DF_source, DF_ref, by = c("POSSN", "nucleotide"))
        # join DF_source and DF_ref and keep all the rows in DF_source

        variantpositions <- unique(DF_ref$POSSN) # identify positions of the variants
        for (k in variantpositions) {
          # replace the allele frequencies from the fasta files with the
          # allele frequencies from the vcf file at variant positions
          temp[which(temp$POSSN == k), "AF.x"] <- DF_ref[which(DF_ref$POSSN == k), "AF"]
        }
        # create new data frame with columns: POSSN, nucleotide,AF and ref
        final <- data.frame(temp$accession, temp$POSSN, temp$nucleotide, temp$AF.x, temp$ref)
        final <- plyr::rename(final, replace = c("temp.accession" = "Accession"))
        final <- plyr::rename(final, replace = c("temp.POSSN" = "POSSN"))
        final <- plyr::rename(final, replace = c("temp.nucleotide" = "nucleotide"))
        final <- plyr::rename(final, replace = c("temp.AF.x" = "AF"))
        final <- plyr::rename(final, replace = c("temp.ref" = "ref"))

        x <- accessionno # accessionno=sample number
        # if the sample name is COVID0007_barcode44, we set n1 to be 07_44:
        # n1<-paste0(str_sub(x,start=8,end=9),"_",str_sub(x,start=-2))
        n1 <- strsplit(x, "[.]")[[1]][1]
        topath <- paste0(destdirpath, n1, suffix) # path to write the data table stored in final to

        readr::write_csv(final, topath) # write csv file
      }

      cl <- makeCluster(numofclusters)

      # Register the parallel backend with the foreach() function
      registerDoParallel(cl)

      func_csv_datatable <- function(name) {
        print(name)
        csv_datatable(name, paste0(inputfiledir, fastainputfilename, "/"), paste0(inputfiledir, vcfinputfilename, "/"), outputfiledir, ".csv")
      }

      foreach(x = names) %dopar% {
        func_csv_datatable(x)
      }

      stopCluster(cl)
    }

    foreach_csv_datatable(names, numclusters, dr, inputfiledir, vcfinputfilename, fastainputfilename, outputfiledir)

    build_network(masterexcelfile, outputfiledir, samplenumber, outputfiledir)
  }
}

# 32 samples: 1hr 21 min
# 3 samples: 7 min
# for (x in 67:83) {
# files named as such: ERR1234567.lofreq.fasta, ERR1234567.lofreq.vcf
# dr = paste0("/Users/windsorkoh/OneDrive - National University of Singapore/Y2 UROPs/hellinger/partitions/pt",x,"/")
#  dr = paste0("/Users/windsorkoh/OneDrive - National University of Singapore/Y2 UROPs/testDataset/lofreq/tinydemo/")
#  finalfn(dr,"vcf","fasta",dr)
#  break
# }
for (i in c(0:(num_partitions - 1))) {
  dr <- paste0(src, "/seqtrack/pt", i, "/")
  finalfn(dr, "vcf", "fasta", dr, num_cl)
}

# generate output file for smk
# file.create("workflow/res/6faster.done")

# comparing processing times
# times <- bench::mark(
# foreach_csv_datatable(names)
# )
# print(times)
